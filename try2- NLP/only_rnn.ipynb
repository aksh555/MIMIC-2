{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,Dense\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "test_val = np.load('test_val.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val = np.load('y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37065, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, Embedding, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squash_function(Layer):\n",
    "    def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "        with tf.name_scope(name, default_name=\"squash\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keep_dims=True)\n",
    "            safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "            squash_factor = squared_norm / (1. + squared_norm)\n",
    "            unit_vector = s / safe_norm\n",
    "            return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1011)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1011, 20)          2227920   \n",
      "_________________________________________________________________\n",
      "squash_function_3 (squash_fu (None, 1011, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1011, 64)          10176     \n",
      "_________________________________________________________________\n",
      "attention_weighted_average_2 (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "squash_function_4 (squash_fu (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1300      \n",
      "=================================================================\n",
      "Total params: 2,239,460\n",
      "Trainable params: 2,239,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/akshara/anaconda3/envs/mimic/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 33358 samples, validate on 3707 samples\n",
      "Epoch 1/5\n",
      "33358/33358 [==============================] - 563s 17ms/step - loss: nan - binary_accuracy: 0.3633 - val_loss: nan - val_binary_accuracy: 0.3000\n",
      "Epoch 2/5\n",
      "33358/33358 [==============================] - 562s 17ms/step - loss: nan - binary_accuracy: 0.3009 - val_loss: nan - val_binary_accuracy: 0.3000\n",
      "Epoch 3/5\n",
      "33358/33358 [==============================] - 530s 16ms/step - loss: nan - binary_accuracy: 0.3009 - val_loss: nan - val_binary_accuracy: 0.3000\n",
      "Epoch 4/5\n",
      "33358/33358 [==============================] - 517s 15ms/step - loss: nan - binary_accuracy: 0.3009 - val_loss: nan - val_binary_accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPooling1D, Dropout, Conv1D,GlobalAveragePooling1D,Bidirectional,GRU,LSTM,concatenate,Input\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "filter_length = 128\n",
    "num_classes = 20\n",
    "max_words = 111396\n",
    "maxlen = 1011\n",
    "\n",
    "input1 = Input(shape=(maxlen,))\n",
    " \n",
    "x = Embedding(max_words, 20, input_length=maxlen)(input1)\n",
    "\n",
    "x = squash_function()(x)\n",
    "\n",
    "x = Bidirectional(GRU(32, return_sequences=True, dropout=0.1,\n",
    "                                                      recurrent_dropout=0.1))(x)\n",
    "\n",
    "\n",
    " \n",
    "#maxpool = GlobalMaxPooling1D()(x)\n",
    "x = AttentionWeightedAverage()(x)\n",
    "\n",
    "x = squash_function()(x)\n",
    " \n",
    "preds = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    " \n",
    "model = keras.Model(input1, preds)\n",
    " \n",
    "model.summary()\n",
    " \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_val)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8177, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[35],y_val[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(7.8654468e-01+           \n",
    "5.0963247e-01+\n",
    "9.6992075e-01+\n",
    "5.8361495e-01+\n",
    "3.5057139e-01+\n",
    "5.7766867e-01)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_round = np.where(y_pred>0.6,1,0)#0.6 enough na lets see....happy ya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3017913024711341\n",
      "0.30179130247113417\n",
      "0.5\n",
      "0.6982086975288658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score,roc_auc_score,confusion_matrix,hamming_loss\n",
    "print(jaccard_score(y_val,y_pred_round,average='micro'))\n",
    "print(jaccard_score(y_val,y_pred_round,average='macro'))\n",
    "print(roc_auc_score(y_val,y_pred_round))\n",
    "print(hamming_loss(y_val,y_pred_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mimic)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
